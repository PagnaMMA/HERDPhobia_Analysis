{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understanding the Dataset and Task\n",
    "The HERDPhobia dataset is organized with three splits:\n",
    "\n",
    "- Training set: Used to train the model\n",
    "- Development (dev) set: Used for validation during training and hyperparameter tuning\n",
    "- Test set: Used only for final evaluation\n",
    "\n",
    "The HERDPhobia dataset is specifically about:\n",
    "\n",
    "Detecting hate speech against Fulani herdsmen in Nigeria\n",
    "Classification into 3 categories:\n",
    "\n",
    "- Hate speech (HT)\n",
    "- Non-hate speech (NHT)\n",
    "- Indeterminate (IND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Environment Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# !pip install transformers datasets pandas numpy scikit-learn torch\n",
    "\n",
    "# Clone the repository\n",
    "#!git clone https://github.com/hausanlp/HERDPhobia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca6268f047c41ba949ef264e48737ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:49:25.773272: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-04 12:49:25.875575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import of important library\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from huggingface_hub import notebook_login\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load and explore all three splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = \"HERDPhobia/data\"\n",
    "train_path = os.path.join(dataset_path, \"train.tsv\")\n",
    "dev_path = os.path.join(dataset_path, \"dev.tsv\")\n",
    "test_path = os.path.join(dataset_path, \"test.tsv\")\n",
    "\n",
    "# Read the data\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "\n",
    "# Explore the data\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Development set size: {len(dev_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "# Check class distribution in all splits\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nClass distribution in dev set:\")\n",
    "print(dev_df['label'].value_counts())\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(test_df['label'].value_counts())\n",
    "\n",
    "# Check for label encoding (if labels are categorical or numerical)\n",
    "print(\"\\nLabel values:\", train_df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the labels are text-based (HT, NHT, IND), we'll need to convert them to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label mapping if necessary\n",
    "label_map = {'HT': 0, 'NHT': 1, 'IND': 2}  # Adjust based on actual label representation\n",
    "\n",
    "# Convert text labels to integers if needed\n",
    "if train_df['label'].dtype == 'object':\n",
    "    train_df['label'] = train_df['label'].map(label_map)\n",
    "    dev_df['label'] = dev_df['label'].map(label_map)\n",
    "    test_df['label'] = test_df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset to a format suitable for Hugging Face's datasets library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Create a DatasetDict with all three splits\n",
    "herdphobia_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': dev_dataset,  # Using 'validation' as it's the standard name in Hugging Face\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "print(herdphobia_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Selection and Fine-tuning Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select an appropriate Afrocentric PLM for Hausa language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an Afrocentric PLM that supports Hausa\n",
    "# Choose an Afrocentric PLM that supports Hausa\n",
    "model_name = \"masakhane/afroxml-r\"  # AfroXLMR\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Tokenize all splits\n",
    "tokenized_datasets = herdphobia_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Prepare for training\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Load model with 3 output classes\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fine-tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1  Updated Metrics Function for 3-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics function for multi-class classification\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Multi-class metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Detailed classification report\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'class_0_f1': report['0']['f1-score'],  # HT class\n",
    "        'class_1_f1': report['1']['f1-score'],  # NHT class\n",
    "        'class_2_f1': report['2']['f1-score']   # IND class\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's leverage the dev set for validation during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(f\"Test set results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Performance Improvement Strategies for Multi-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's class imbalance\n",
    "train_label_counts = train_df['label'].value_counts()\n",
    "print(\"Label distribution:\", train_label_counts)\n",
    "\n",
    "# Calculate class weights if needed\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Apply class weights in the model\n",
    "# Note: You would typically do this inside the model's forward pass\n",
    "# But with Hugging Face, we need a custom training loop or a custom model\n",
    "# For simplicity, we'll use weighted data augmentation instead\n",
    "\n",
    "# Weighted data augmentation for minority classes\n",
    "def create_balanced_augmented_dataset(df, class_counts):\n",
    "    # Find the majority class count\n",
    "    max_count = class_counts.max()\n",
    "    \n",
    "    # Create dataframes for each class\n",
    "    class_dfs = {}\n",
    "    for class_label in class_counts.index:\n",
    "        class_dfs[class_label] = df[df['label'] == class_label]\n",
    "    \n",
    "    # Augment each class to reach similar size as majority class\n",
    "    augmented_dfs = []\n",
    "    for class_label, class_df in class_dfs.items():\n",
    "        if len(class_df) < max_count:\n",
    "            # Calculate how many times to duplicate\n",
    "            augment_factor = int(np.ceil(max_count / len(class_df))) - 1\n",
    "            \n",
    "            # Apply augmentation\n",
    "            augmented_class_df = class_df.copy()\n",
    "            for _ in range(augment_factor):\n",
    "                # Apply text augmentation to the minority class\n",
    "                augmented_texts = []\n",
    "                augmented_labels = []\n",
    "                \n",
    "                for _, row in class_df.iterrows():\n",
    "                    # Apply simple augmentation (you can use the techniques defined earlier)\n",
    "                    # For now, just duplicate the example\n",
    "                    augmented_texts.append(row['text'])\n",
    "                    augmented_labels.append(row['label'])\n",
    "                \n",
    "                temp_df = pd.DataFrame({\n",
    "                    'text': augmented_texts,\n",
    "                    'label': augmented_labels\n",
    "                })\n",
    "                \n",
    "                augmented_class_df = pd.concat([augmented_class_df, temp_df], ignore_index=True)\n",
    "            \n",
    "            # Take only what we need to balance\n",
    "            augmented_class_df = augmented_class_df.sample(max_count, replace=False)\n",
    "            augmented_dfs.append(augmented_class_df)\n",
    "        else:\n",
    "            augmented_dfs.append(class_df)\n",
    "    \n",
    "    # Combine all balanced classes\n",
    "    balanced_df = pd.concat(augmented_dfs, ignore_index=True)\n",
    "    return balanced_df\n",
    "\n",
    "# Create a more balanced dataset\n",
    "balanced_train_df = create_balanced_augmented_dataset(train_df, train_label_counts)\n",
    "print(f\"Original training set size: {len(train_df)}\")\n",
    "print(f\"Balanced training set size: {len(balanced_train_df)}\")\n",
    "print(\"New class distribution:\", balanced_train_df['label'].value_counts())\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "balanced_train_dataset = Dataset.from_pandas(balanced_train_df)\n",
    "balanced_dataset_dict = DatasetDict({\n",
    "    'train': balanced_train_dataset,\n",
    "    'validation': dev_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# Tokenize the balanced dataset\n",
    "tokenized_balanced_datasets = balanced_dataset_dict.map(tokenize_function, batched=True)\n",
    "tokenized_balanced_datasets = tokenized_balanced_datasets.remove_columns([\"text\"])\n",
    "tokenized_balanced_datasets = tokenized_balanced_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_balanced_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Advanced Fine-tuning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up improved training arguments\n",
    "improved_training_args = TrainingArguments(\n",
    "    output_dir=\"./improved_results\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,  # Mixed precision training\n",
    "    warmup_ratio=0.1,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "# Initialize improved trainer with balanced dataset\n",
    "improved_trainer = Trainer(\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3),\n",
    "    args=improved_training_args,\n",
    "    train_dataset=tokenized_balanced_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_balanced_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train improved model\n",
    "improved_trainer.train()\n",
    "\n",
    "# Evaluate improved model\n",
    "improved_test_results = improved_trainer.evaluate(tokenized_balanced_datasets[\"test\"])\n",
    "print(f\"Improved model results: {improved_test_results}\")\n",
    "\n",
    "# Display per-class performance\n",
    "print(\"Per-class F1 scores:\")\n",
    "print(f\"Hate speech (HT): {improved_test_results['eval_class_0_f1']:.4f}\")\n",
    "print(f\"Non-hate speech (NHT): {improved_test_results['eval_class_1_f1']:.4f}\")\n",
    "print(f\"Indeterminate (IND): {improved_test_results['eval_class_2_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the model\n",
    "test_predictions = improved_trainer.predict(tokenized_balanced_datasets[\"test\"])\n",
    "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "true_labels = tokenized_balanced_datasets[\"test\"][\"labels\"]\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "class_names = [\"HT\", \"NHT\", \"IND\"]  # Replace with actual class names\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Calculate per-class metrics\n",
    "print(\"Detailed classification report:\")\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Error Analysis and Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples where the model made mistakes\n",
    "def get_error_examples(test_dataset, true_labels, predicted_labels, n=10):\n",
    "    error_indices = np.where(true_labels != predicted_labels)[0]\n",
    "    \n",
    "    if len(error_indices) == 0:\n",
    "        print(\"No errors found!\")\n",
    "        return\n",
    "    \n",
    "    # Select a random sample of errors (up to n)\n",
    "    sample_size = min(n, len(error_indices))\n",
    "    selected_indices = np.random.choice(error_indices, size=sample_size, replace=False)\n",
    "    \n",
    "    # Get the original text and labels\n",
    "    error_examples = []\n",
    "    for idx in selected_indices:\n",
    "        example = {\n",
    "            'text': test_df.iloc[idx]['text'],\n",
    "            'true_label': class_names[true_labels[idx]],\n",
    "            'predicted_label': class_names[predicted_labels[idx]]\n",
    "        }\n",
    "        error_examples.append(example)\n",
    "    \n",
    "    return error_examples\n",
    "\n",
    "error_examples = get_error_examples(test_df, true_labels, predicted_labels)\n",
    "\n",
    "print(\"Error Analysis:\")\n",
    "for i, example in enumerate(error_examples):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Text: {example['text']}\")\n",
    "    print(f\"True label: {example['true_label']}\")\n",
    "    print(f\"Predicted label: {example['predicted_label']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Publishing to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's publish our best model to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Hugging Face\n",
    "notebook_login()\n",
    "\n",
    "# Choose the best model\n",
    "best_trainer = improved_trainer\n",
    "\n",
    "# Create a model card\n",
    "model_card = \"\"\"\n",
    "---\n",
    "language: hau\n",
    "license: mit\n",
    "datasets:\n",
    "  - hausanlp/HERDPhobia\n",
    "tags:\n",
    "  - hate-speech-detection\n",
    "  - hausa\n",
    "  - african-nlp\n",
    "  - fulani-herdsmen\n",
    "---\n",
    "\n",
    "# HERDPhobia Hate Speech Detection Model\n",
    "\n",
    "This model is fine-tuned on the HERDPhobia dataset for detecting hate speech against Fulani herdsmen in Nigeria in Hausa language text.\n",
    "\n",
    "## Model Description\n",
    "\n",
    "This model is based on [masakhane/afroxml-r](https://huggingface.co/masakhane/afroxml-r) fine-tuned on the HERDPhobia dataset. It performs 3-class classification:\n",
    "- Hate speech (HT)\n",
    "- Non-hate speech (NHT)\n",
    "- Indeterminate (IND)\n",
    "\n",
    "## Intended Use\n",
    "\n",
    "This model is intended for detecting hate speech against Fulani herdsmen in Hausa language text from social media and other online sources.\n",
    "\n",
    "## Training Data\n",
    "\n",
    "The model was trained on the HERDPhobia dataset, which contains annotated tweets in Hausa.\n",
    "\n",
    "## Performance\n",
    "\n",
    "The model achieves the following scores on the test set:\n",
    "- Overall Accuracy: {improved_test_results['eval_accuracy']:.4f}\n",
    "- Overall F1 Score: {improved_test_results['eval_f1']:.4f}\n",
    "- Per-class F1 scores:\n",
    "  - Hate speech (HT): {improved_test_results['eval_class_0_f1']:.4f}\n",
    "  - Non-hate speech (NHT): {improved_test_results['eval_class_1_f1']:.4f}\n",
    "  - Indeterminate (IND): {improved_test_results['eval_class_2_f1']:.4f}\n",
    "\n",
    "## Improvement Strategies\n",
    "\n",
    "1. Class balancing techniques were applied to handle uneven class distribution\n",
    "2. Hyperparameter optimization improved overall performance\n",
    "3. Error analysis was conducted to understand model limitations\n",
    "\n",
    "## Limitations\n",
    "\n",
    "This model may have limitations in detecting subtle forms of hate speech or hate speech expressed in dialects or slang not well-represented in the training data.\n",
    "\"\"\"\n",
    "\n",
    "# Save the model card\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(model_card)\n",
    "\n",
    "# Push to Hugging Face Hub\n",
    "model_name_on_hub = \"YOUR_USERNAME/hausa-herdphobia-classifier\"  # Replace with your username\n",
    "\n",
    "best_trainer.push_to_hub(\n",
    "    repo_id=model_name_on_hub,\n",
    "    commit_message=\"Add fine-tuned model for Hausa hate speech detection against Fulani herdsmen\"\n",
    ")\n",
    "\n",
    "print(f\"Model successfully pushed to {model_name_on_hub}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusion and Analysis Report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
